# argyle-scanner

PROGRESS OVERVIEW
The Upwork application was analyzed with Burp Suite Interceptor to understand the communications between the browser application and the Upwork servers. It became evident that a third party tool is employed on the Upwork front end to obfuscate the authentication credentials and similarly necessary communications between the browser and Upwork systems. Because of this, the original plan of employing the simpler Python requests module to conduct the application communications for operating the Upwork system as a given user was abandoned due to time constrains. To quickly set up a scraping enviroment capable of traversing the Upwork system, the browser automation tool Selenium was employed and commanded with the Python 3 programming language.
The routines for moving through the Upwork application are contained in a Python object called UpworkSeleniumTraverser. The current implemented functionality enables the bot to move through primary and secondary authentication interfaces, as well as the view profile, main dashboard, and contact info interfaces to collect the required information as specified by the Argyle profile docs. Because the HTML element identifiers changed multiple times while conducting testing, the elements which are interacted with in each interface are stored in a JSON formatted configuration file, along with the credentials of the account to investigate.
Because each interface's components and their actions/identifiers are very similar, the element existence verification and engagement routines are able to be abstracted into UpworkSeleniumTraverser methods which operate in accordance to the component objects specified in the config file.
A Pydantic class is available to verify that the required user account information is present and in the case of the user address object formatted correctly, and a method to serialize the data as a JSON object.

PROJECT CHALLENGES
Initially the fact that the client/server communications are well obfuscated was challenging to quickly replicate with the requests module, thus the Selenium tool was very useful as it abstracts away the entire process of reverse engineering the communications protocols. Next, the HTML identifiers for the required interaction components were not static, thus it became obvious that they should all be centralized together for simple modifications when the interface shifts identifiers. Additionally the rendering of the application throws error if it is attempted to be read proir to the necessary AJAX loads are complete, which were combatted with time.sleep calls to halt execution enough for the rendering process to complete.

FUTURE WORK
The Pydantic data validator class should be utilized to verify that the account extracted information is present, and additional validator methods should be enumerated such that all of the required information is formatted correctly. Next, the sleeping parameters should be extracted to the config file or replaced with routines to monitor the interface for the rendering of all required components. Next to enable the rapid utilization of the program for multiple accounts simultaneously, a collection of proxy credentials should be added to the config file then randomly selected and passed to the UpworkSeleniumTraverser at initialization, as the Upwork backend blocks more than approximately two users from operating from the same machine, most likely identified by the IP address, though the headless browser mode should also be employed and randomly configured to appear as a distinct interface for each scraping session.
